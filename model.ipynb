{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61fec990-7828-4e47-955e-b68ca857e04d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbeafaf-5bb8-479e-b72c-1dbb5890b371",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff60767-58ab-45f9-b659-41197558ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-ins\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import traceback\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# common\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# misc\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "from termcolor import colored\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# metrics\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fba2b0-4b6f-4b4d-b25f-95d4b6df3254",
   "metadata": {},
   "source": [
    "### Initial tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde7130-45a6-4259-8830-0d0263e8c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# suppress warnings\n",
    "import sys, os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# also suppress warnings of parallel processes such as grid search cv\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "# configure pandas\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30543f6b-8ac9-4bfd-a49e-c46bf4c816b9",
   "metadata": {},
   "source": [
    "### Utils / Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7849014-1618-4956-a7f1-aa2730b85eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cprint(text, color):\n",
    "    print(colored(text, color, attrs=['bold']))\n",
    "    \n",
    "def print_red(text):\n",
    "    cprint(text, 'red')\n",
    "\n",
    "def print_blue(text):\n",
    "    cprint(text, 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ce119-f6c8-41ea-b213-a5d2ab61a4d4",
   "metadata": {},
   "source": [
    "### Path Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a34fb-edec-489b-ac7d-2934fac36ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '.'\n",
    "path_dataset = path.join(path_root, 'dataset')\n",
    "path_csv = path.join(path_dataset, 'csv')\n",
    "path_csv_output =  path_csv\n",
    "path_models = path.join(path_root, 'models')\n",
    "    \n",
    "# Create directories.\n",
    "Path(path_models).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f106a9-9b2f-4917-87d9-822a03307d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintDuration(object):\n",
    "    class printer(str):\n",
    "        def __repr__(self):\n",
    "            return self\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start_time = datetime.now()\n",
    "        self.last_tick = self.start_time\n",
    "        self.tick_count = 0\n",
    "        self.tick_times = 0\n",
    "        \n",
    "        self.completed = False\n",
    "        self.progress = 0\n",
    "        self.ert = 0\n",
    "        self.att = 0\n",
    "        self.out = None\n",
    "        \n",
    "        return self.tick\n",
    "  \n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        if exc_type is not None:\n",
    "            traceback.print_exception(exc_type, exc_value, tb)\n",
    "        \n",
    "        self.completed = True\n",
    "        self.render()\n",
    "        \n",
    "    def tdformat(self, seconds):\n",
    "        hours, remainder = divmod(seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n",
    "    \n",
    "    def render(self):\n",
    "        output = ''\n",
    "        \n",
    "        if self.completed:\n",
    "            complete_time = (datetime.now() - self.start_time).total_seconds()\n",
    "            complete_time = self.tdformat(complete_time)\n",
    "            output = f'100% completed, total run time = {complete_time}'\n",
    "        else:\n",
    "            percent = round(self.progress * 100)\n",
    "            att = self.tdformat(self.att)\n",
    "            ert = self.tdformat(self.ert)\n",
    "            output = f'{percent}% completed, remaining time = {ert}, avg ticktime = {att}'\n",
    "        \n",
    "        output = self.printer(output)\n",
    "        \n",
    "        if self.out is None:\n",
    "            self.out = display(output, display_id=True)\n",
    "        else:\n",
    "            self.out.update(output)\n",
    "    \n",
    "    def tick(self, progress):\n",
    "        now = datetime.now()\n",
    "        \n",
    "        # calculate\n",
    "        work_time = (now - self.start_time).total_seconds()\n",
    "        tick_time = (now - self.last_tick).total_seconds()\n",
    "        self.tick_count += 1\n",
    "        self.tick_times += tick_time\n",
    "        avg_tick_time = self.tick_times // self.tick_count\n",
    "        \n",
    "        if progress > 0:\n",
    "            total_ticks = self.tick_count // progress\n",
    "            remained_ticks = total_ticks - self.tick_count\n",
    "            est_remain_time = avg_tick_time * remained_ticks\n",
    "        else:\n",
    "            est_remain_time = 0\n",
    "            \n",
    "        # set\n",
    "        self.progress = progress\n",
    "        self.att = avg_tick_time\n",
    "        self.ert = est_remain_time\n",
    "        \n",
    "        # render\n",
    "        self.render() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d04cc1-c4f0-4e7f-b701-9673b5599813",
   "metadata": {},
   "source": [
    "### Detect Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b86de6-5402-4905-9f14-8ca83226e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4fc0d-3aff-4294-8df8-aa3a8980e199",
   "metadata": {},
   "source": [
    "### Path Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d230ae-2513-4cb8-aac0-e92acf95f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '.'\n",
    "path_dataset = path.join(path_root, 'dataset')\n",
    "path_csv = path.join(path_dataset, 'csv')\n",
    "path_csv_output =  path_csv\n",
    "path_models = path.join(path_root, 'models')\n",
    "\n",
    "if ENV_KAGGLE:\n",
    "    path_root = '/kaggle/working'\n",
    "    path_dataset = '/kaggle'\n",
    "    path_csv = path.join(path_dataset, 'csv')\n",
    "    path_csv_output = path_root\n",
    "    path_models = path.join(path_root, 'models')\n",
    "    \n",
    "# Create directories.\n",
    "Path(path_models).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd412b4-af60-4de8-bbe5-5d6d54fabb32",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069bbe4-908e-4347-984d-f91785da4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_autosave_models = False\n",
    "cfg_force_train = False\n",
    "\n",
    "if ENV_KAGGLE:\n",
    "    cfg_autosave_models = True\n",
    "    cfg_force_train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cb0ce-1866-4eea-8af9-27b544fe93d1",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab744b3a-9a7f-44e8-a8e3-913a3e64e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_seed = 7908\n",
    "hp_cv_splits = 10\n",
    "hp_test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6f79a-5a50-487a-844b-e3571c0cd848",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3777b2-af4a-4803-8a53-0f147562ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(path.join(path_csv, 'data.csv'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61b15a-a819-4ace-b7cf-5ca03d9c466f",
   "metadata": {},
   "source": [
    "### Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa4f1b-4481-4ce8-9ddb-709c84583a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457abc1b-aed7-4cc2-bf9d-ad7a5ce39046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0075fbe-9745-4e3b-8d45-783a12f5a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353a038-e5e1-46a8-878b-e25633ead766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c51cac-4c2e-4958-81db-e47f96da4d91",
   "metadata": {},
   "source": [
    "# Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5ba61-c8a4-4698-9973-f10aa032ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemover:\n",
    "    @staticmethod\n",
    "    def numeric(data):\n",
    "        cols = data.select_dtypes(include=['float64', 'int64']).columns.to_list()\n",
    "        return OutlierRemover(cols)\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.bands = {}\n",
    "    \n",
    "    def fit(self, data):\n",
    "        for col in self.cols:\n",
    "            Q1 = data[col].quantile(0.25)\n",
    "            Q3 = data[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_band = Q1 - 1.5 * IQR\n",
    "            upper_band = Q3 + 1.5 * IQR\n",
    "            \n",
    "            self.bands[col] = (lower_band, upper_band)\n",
    "    \n",
    "    def transform(self, data):\n",
    "        for col in self.cols:\n",
    "            lower_band, upper_band = self.bands[col]\n",
    "            inliers = ~((data[col] < lower_band) | (data[col] > upper_band))\n",
    "            data = data[inliers]\n",
    "            \n",
    "        return data\n",
    "            \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "class MultiLabelEncoder():\n",
    "    @staticmethod\n",
    "    def binary(data):\n",
    "        cols = [col for col in data.columns if data[col].nunique() == 2]\n",
    "        return MultiLabelEncoder(cols)\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.encoders = {col: LabelEncoder() for col in cols}\n",
    "    \n",
    "    def fit(self, data):\n",
    "        for col in self.cols:\n",
    "            self.encoders[col].fit(data[col])\n",
    "\n",
    "    def transform(self, data):\n",
    "        for col in self.cols:\n",
    "            data[col] = self.encoders[col].transform(data[col])\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "class Preprocessor:\n",
    "    @staticmethod\n",
    "    def process(*args, **kwargs):\n",
    "        processor = Preprocessor(*args, **kwargs)\n",
    "        processor.apply()\n",
    "        return processor\n",
    "    \n",
    "    def __init__(self, data, test_index, train_index, options={}):\n",
    "        self.data = data\n",
    "        self.test_index = np.array(test_index)\n",
    "        self.train_index = np.array(train_index)\n",
    "        self.options = options\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.data.loc[self.test_index]\n",
    "    \n",
    "    @test.setter\n",
    "    def test(self, value):\n",
    "        self.data.loc[self.test_index] = value\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.data.loc[self.train_index]\n",
    "    \n",
    "    @train.setter\n",
    "    def train(self, value):\n",
    "        self.data.loc[self.train_index] = value\n",
    "\n",
    "    def x(self, dframe):\n",
    "        return dframe.drop(self.options['target'], axis=1).to_numpy()\n",
    "    \n",
    "    def y(self, dframe):\n",
    "        return dframe[self.options['target']].to_numpy()\n",
    "        \n",
    "    @property\n",
    "    def x_test(self):\n",
    "        return self.x(self.test)\n",
    "        \n",
    "    @property\n",
    "    def x_train(self):\n",
    "        return self.x(self.train)\n",
    "    \n",
    "    @property\n",
    "    def y_test(self):\n",
    "        return self.y(self.test)\n",
    "        \n",
    "    @property\n",
    "    def y_train(self):\n",
    "        return self.y(self.train)\n",
    "    \n",
    "    def chop(self):\n",
    "        return self.x_test, self.y_test, self.x_train, self.y_train\n",
    "    \n",
    "    def apply(self):\n",
    "        # remove outliers\n",
    "        outlier_strategy = self.options.get('outlier_strategy', 'train_only')\n",
    "        outlier_remover = OutlierRemover.numeric(self.data)\n",
    "        match outlier_strategy:\n",
    "            case 'train_only':\n",
    "                self.train = outlier_remover.fit_transform(self.train)\n",
    "            case 'include_test':\n",
    "                outlier_remover.fit(self.train())\n",
    "                self.data = outlier_remover.transform(self.data)\n",
    "            case 'all':\n",
    "                self.data = outlier_remover.fit_transform(self.data)\n",
    "        \n",
    "        # update removed indexes.\n",
    "        self.train_index = self.train_index[np.isin(self.train_index, self.data.index.values)]\n",
    "        self.test_index = self.test_index[np.isin(self.test_index, self.data.index.values)]\n",
    "        \n",
    "        # encode labels\n",
    "        encode_labels = self.options.get('encode_labels', True)\n",
    "        if encode_labels:\n",
    "            self.data = MultiLabelEncoder.binary(self.data).fit_transform(self.data)\n",
    "            \n",
    "        onehot_encoding = self.options.get('onehot_encoding', None)\n",
    "        if onehot_encoding is not None:\n",
    "            cols = onehot_encoding\n",
    "            self.data = pd.get_dummies(self.data, columns=cols, prefix=cols)\n",
    "        \n",
    "        # ordinal encoding\n",
    "        ordinal_encoding = self.options.get('ordinal_encoding', None)\n",
    "        if ordinal_encoding is not None:\n",
    "            for col, ordinals in ordinal_encoding.items():\n",
    "                encoder = OrdinalEncoder(categories=[ordinals])\n",
    "                self.data[[col]] = encoder.fit_transform(self.data[[col]])\n",
    "        \n",
    "        # scaler\n",
    "        scale = self.options.get('scale', True)\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            self.train = scaler.fit_transform(self.train)\n",
    "            self.test = scaler.transform(self.test)\n",
    "\n",
    "# remove\n",
    "split = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "train_index, test_index = next(iter(split.split(df)))\n",
    "\n",
    "options = {\n",
    "    'target': 'HeartDisease',\n",
    "    'outlier_strategy': 'all',\n",
    "    'encode_labels': True,\n",
    "    'onehot_encoding': ['Race', 'Diabetic'],\n",
    "    'ordinal_encoding': {\n",
    "        'GenHealth': ['Poor', 'Fair', 'Good', 'Very good','Excellent'],\n",
    "        'AgeCategory': ['18-24', '25-29','30-34', '35-39', '40-44', '45-49', '50-54',\n",
    "                        '55-59', '60-64', '65-69', '70-74', '75-79', '80 or older']\n",
    "    }\n",
    "}\n",
    "\n",
    "preprocessor = Preprocessor.process(df, test_index, train_index, options)\n",
    "X_test, Y_test, X_train, Y_train = preprocessor.chop()\n",
    "print(X_test.shape, Y_test.shape, X_train.shape, Y_train.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
