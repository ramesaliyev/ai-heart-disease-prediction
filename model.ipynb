{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61fec990-7828-4e47-955e-b68ca857e04d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbeafaf-5bb8-479e-b72c-1dbb5890b371",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff60767-58ab-45f9-b659-41197558ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-ins\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import traceback\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# common\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# misc\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "from termcolor import colored\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# metrics\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "\n",
    "# training\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fba2b0-4b6f-4b4d-b25f-95d4b6df3254",
   "metadata": {},
   "source": [
    "### Initial tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde7130-45a6-4259-8830-0d0263e8c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# suppress warnings\n",
    "import sys, os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# also suppress warnings of parallel processes such as grid search cv\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "# configure pandas\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30543f6b-8ac9-4bfd-a49e-c46bf4c816b9",
   "metadata": {},
   "source": [
    "### Utils / Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7849014-1618-4956-a7f1-aa2730b85eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(a, b):\n",
    "    return {**a, **b}\n",
    "\n",
    "def cprint(text, color):\n",
    "    print(colored(text, color, attrs=['bold']))\n",
    "    \n",
    "def print_red(text):\n",
    "    cprint(text, 'red')\n",
    "\n",
    "def print_blue(text):\n",
    "    cprint(text, 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ce119-f6c8-41ea-b213-a5d2ab61a4d4",
   "metadata": {},
   "source": [
    "### Path Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a34fb-edec-489b-ac7d-2934fac36ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '.'\n",
    "path_dataset = path.join(path_root, 'dataset')\n",
    "path_csv = path.join(path_dataset, 'csv')\n",
    "path_csv_output =  path_csv\n",
    "path_models = path.join(path_root, 'models')\n",
    "    \n",
    "# Create directories.\n",
    "Path(path_models).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f106a9-9b2f-4917-87d9-822a03307d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintDuration(object):\n",
    "    class printer(str):\n",
    "        def __repr__(self):\n",
    "            return self\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start_time = datetime.now()\n",
    "        self.last_tick = self.start_time\n",
    "        self.tick_count = 0\n",
    "        self.tick_times = 0\n",
    "        \n",
    "        self.completed = False\n",
    "        self.progress = 0\n",
    "        self.ert = 0\n",
    "        self.att = 0\n",
    "        self.out = None\n",
    "        \n",
    "        return self.tick\n",
    "  \n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        if exc_type is not None:\n",
    "            traceback.print_exception(exc_type, exc_value, tb)\n",
    "        \n",
    "        self.completed = True\n",
    "        self.render()\n",
    "        \n",
    "    def tdformat(self, seconds):\n",
    "        hours, remainder = divmod(seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n",
    "    \n",
    "    def render(self):\n",
    "        output = ''\n",
    "        \n",
    "        if self.completed:\n",
    "            complete_time = (datetime.now() - self.start_time).total_seconds()\n",
    "            complete_time = self.tdformat(complete_time)\n",
    "            output = f'100% completed, total run time = {complete_time}'\n",
    "        else:\n",
    "            percent = round(self.progress * 100)\n",
    "            att = self.tdformat(self.att)\n",
    "            ert = self.tdformat(self.ert)\n",
    "            output = f'{percent}% completed, remaining time = {ert}, avg ticktime = {att}'\n",
    "        \n",
    "        output = self.printer(output)\n",
    "        \n",
    "        if self.out is None:\n",
    "            self.out = display(output, display_id=True)\n",
    "        else:\n",
    "            self.out.update(output)\n",
    "    \n",
    "    def tick(self, progress):\n",
    "        now = datetime.now()\n",
    "        \n",
    "        # calculate\n",
    "        work_time = (now - self.start_time).total_seconds()\n",
    "        tick_time = (now - self.last_tick).total_seconds()\n",
    "        self.tick_count += 1\n",
    "        self.tick_times += tick_time\n",
    "        avg_tick_time = self.tick_times // self.tick_count\n",
    "        \n",
    "        if progress > 0:\n",
    "            total_ticks = self.tick_count // progress\n",
    "            remained_ticks = total_ticks - self.tick_count\n",
    "            est_remain_time = avg_tick_time * remained_ticks\n",
    "        else:\n",
    "            est_remain_time = 0\n",
    "            \n",
    "        # set\n",
    "        self.progress = progress\n",
    "        self.att = avg_tick_time\n",
    "        self.ert = est_remain_time\n",
    "        \n",
    "        # render\n",
    "        self.render() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d04cc1-c4f0-4e7f-b701-9673b5599813",
   "metadata": {},
   "source": [
    "### Detect Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b86de6-5402-4905-9f14-8ca83226e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4fc0d-3aff-4294-8df8-aa3a8980e199",
   "metadata": {},
   "source": [
    "### Path Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d230ae-2513-4cb8-aac0-e92acf95f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '.'\n",
    "path_dataset = path.join(path_root, 'dataset')\n",
    "path_csv = path.join(path_dataset, 'csv')\n",
    "path_csv_output =  path_csv\n",
    "path_models = path.join(path_root, 'models')\n",
    "\n",
    "if ENV_KAGGLE:\n",
    "    path_root = '/kaggle/working'\n",
    "    path_dataset = '/kaggle'\n",
    "    path_csv = path.join(path_dataset, 'csv')\n",
    "    path_csv_output = path_root\n",
    "    path_models = path.join(path_root, 'models')\n",
    "    \n",
    "# Create directories.\n",
    "Path(path_models).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd412b4-af60-4de8-bbe5-5d6d54fabb32",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069bbe4-908e-4347-984d-f91785da4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_autosave_models = False\n",
    "cfg_force_train = False\n",
    "\n",
    "if ENV_KAGGLE:\n",
    "    cfg_autosave_models = True\n",
    "    cfg_force_train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cb0ce-1866-4eea-8af9-27b544fe93d1",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab744b3a-9a7f-44e8-a8e3-913a3e64e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_seed = 7908\n",
    "hp_cv_splits = 10\n",
    "hp_test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6f79a-5a50-487a-844b-e3571c0cd848",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3777b2-af4a-4803-8a53-0f147562ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "data = pd.read_csv(path.join(path_csv, 'data.csv'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61b15a-a819-4ace-b7cf-5ca03d9c466f",
   "metadata": {},
   "source": [
    "### Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa4f1b-4481-4ce8-9ddb-709c84583a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457abc1b-aed7-4cc2-bf9d-ad7a5ce39046",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0075fbe-9745-4e3b-8d45-783a12f5a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353a038-e5e1-46a8-878b-e25633ead766",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c51cac-4c2e-4958-81db-e47f96da4d91",
   "metadata": {},
   "source": [
    "# Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5ba61-c8a4-4698-9973-f10aa032ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemover:\n",
    "    @staticmethod\n",
    "    def numeric(data):\n",
    "        cols = data.select_dtypes(include=['float64', 'int64']).columns.to_list()\n",
    "        return OutlierRemover(cols)\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.bands = {}\n",
    "    \n",
    "    def fit(self, data):\n",
    "        for col in self.cols:\n",
    "            Q1 = data[col].quantile(0.25)\n",
    "            Q3 = data[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_band = Q1 - 1.5 * IQR\n",
    "            upper_band = Q3 + 1.5 * IQR\n",
    "            \n",
    "            self.bands[col] = (lower_band, upper_band)\n",
    "    \n",
    "    def transform(self, data):\n",
    "        for col in self.cols:\n",
    "            lower_band, upper_band = self.bands[col]\n",
    "            inliers = ~((data[col] < lower_band) | (data[col] > upper_band))\n",
    "            data = data[inliers]\n",
    "            \n",
    "        return data\n",
    "            \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "class MultiLabelEncoder():\n",
    "    @staticmethod\n",
    "    def binary(data):\n",
    "        cols = [col for col in data.columns if data[col].nunique() == 2]\n",
    "        return MultiLabelEncoder(cols)\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.encoders = {col: LabelEncoder() for col in cols}\n",
    "    \n",
    "    def fit(self, data):\n",
    "        for col in self.cols:\n",
    "            self.encoders[col].fit(data[col])\n",
    "\n",
    "    def transform(self, data):\n",
    "        for col in self.cols:\n",
    "            data[col] = self.encoders[col].transform(data[col])\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "class Preprocessor:\n",
    "    @staticmethod\n",
    "    def process(*args, **kwargs):\n",
    "        processor = Preprocessor(*args, **kwargs)\n",
    "        processor.apply()\n",
    "        return processor\n",
    "    \n",
    "    def __init__(self, data, test_index, train_index, options={}):\n",
    "        self.data = data\n",
    "        self.test_index = np.array(test_index)\n",
    "        self.train_index = np.array(train_index)\n",
    "        self.options = options\n",
    "        \n",
    "        self.target = self.options['target']\n",
    "        self.features = self.data.columns != self.target\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.data.loc[self.test_index]\n",
    "    \n",
    "    @test.setter\n",
    "    def test(self, value):\n",
    "        self.data.loc[self.test_index] = value\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.data.loc[self.train_index]\n",
    "    \n",
    "    @train.setter\n",
    "    def train(self, value):\n",
    "        self.data.loc[self.train_index] = value\n",
    "\n",
    "    def x(self, dframe):\n",
    "        return dframe.drop(self.target, axis=1).to_numpy()\n",
    "    \n",
    "    def y(self, dframe):\n",
    "        return dframe[self.target].to_numpy()\n",
    "        \n",
    "    @property\n",
    "    def x_test(self):\n",
    "        return self.x(self.test)\n",
    "    \n",
    "    @x_test.setter\n",
    "    def x_test(self, value):\n",
    "        self.data.loc[self.test_index, self.features] = value\n",
    "        \n",
    "    @property\n",
    "    def x_train(self):\n",
    "        return self.x(self.train)\n",
    "    \n",
    "    @x_train.setter\n",
    "    def x_train(self, value):\n",
    "        self.data.loc[self.train_index, self.features] = value\n",
    "    \n",
    "    @property\n",
    "    def y_test(self):\n",
    "        return self.y(self.test)\n",
    "        \n",
    "    @property\n",
    "    def y_train(self):\n",
    "        return self.y(self.train)\n",
    "    \n",
    "    def chop(self):\n",
    "        return self.x_test, self.y_test, self.x_train, self.y_train\n",
    "    \n",
    "    def apply(self):\n",
    "        # remove outliers\n",
    "        outlier_strategy = self.options.get('outlier_strategy', 'train_only')\n",
    "        outlier_remover = OutlierRemover.numeric(self.data)\n",
    "        match outlier_strategy:\n",
    "            case 'train_only':\n",
    "                self.train = outlier_remover.fit_transform(self.train)\n",
    "            case 'include_test':\n",
    "                outlier_remover.fit(self.train())\n",
    "                self.data = outlier_remover.transform(self.data)\n",
    "            case 'all':\n",
    "                self.data = outlier_remover.fit_transform(self.data)\n",
    "        \n",
    "        # update removed indexes.\n",
    "        indexes = self.data.index.values\n",
    "        self.train_index = self.train_index[np.isin(self.train_index, indexes)]\n",
    "        self.test_index = self.test_index[np.isin(self.test_index, indexes)]\n",
    "        \n",
    "        # encode labels\n",
    "        encode_labels = self.options.get('encode_labels', True)\n",
    "        if encode_labels:\n",
    "            self.data = MultiLabelEncoder.binary(self.data).fit_transform(self.data)\n",
    "            \n",
    "        onehot_encoding = self.options.get('onehot_encoding', None)\n",
    "        if onehot_encoding is not None:\n",
    "            cols = onehot_encoding\n",
    "            self.data = pd.get_dummies(self.data, columns=cols, prefix=cols)\n",
    "            self.features = self.data.columns != self.target\n",
    "            \n",
    "        # ordinal encoding\n",
    "        ordinal_encoding = self.options.get('ordinal_encoding', None)\n",
    "        if ordinal_encoding is not None:\n",
    "            for col, ordinals in ordinal_encoding.items():\n",
    "                encoder = OrdinalEncoder(categories=[ordinals])\n",
    "                self.data[[col]] = encoder.fit_transform(self.data[[col]])\n",
    "        \n",
    "        # scaler\n",
    "        scale = self.options.get('scale', True)\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            self.x_train = scaler.fit_transform(self.x_train)\n",
    "            self.x_test = scaler.transform(self.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74c236-cab3-4c93-93b8-222d7650a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, estimator, data, n_splits, test_size, seed,\n",
    "                 prep_params={}, hp_grid=None):\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.data = data\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.seed = seed\n",
    "        self.prep_params = prep_params\n",
    "        self.hp_grid = hp_grid\n",
    "        \n",
    "        self.stats = []\n",
    "        self.best_stats = None\n",
    "        self.best_estimator = None\n",
    "    \n",
    "    def split(self):\n",
    "        split = ShuffleSplit(n_splits=self.n_splits, test_size=self.test_size, random_state=self.seed)\n",
    "        return split.split(self.data)\n",
    "    \n",
    "    def train(self, tick=None):\n",
    "        for split_index, (train_index, test_index) in enumerate(self.split()):\n",
    "            if tick is not None:\n",
    "                tick(split_index/self.n_splits)\n",
    "            \n",
    "            preprocessor = Preprocessor.process(self.data, test_index, train_index, self.prep_params)\n",
    "            X_test, Y_test, X_train, Y_train = preprocessor.chop()\n",
    "            \n",
    "            estimator = self.estimator()\n",
    "            \n",
    "            # default values\n",
    "            best_params = None\n",
    "            best_estimator = estimator\n",
    "            \n",
    "            # fit estimator\n",
    "            if self.hp_grid is not None:\n",
    "                cv = GridSearchCV(estimator, self.hp_grid, cv=self.n_splits, n_jobs=-1)\n",
    "                cv.fit(X_train, Y_train)\n",
    "                \n",
    "                best_params = cv.best_params_\n",
    "                best_estimator = cv.best_estimator_\n",
    "            else:\n",
    "                best_estimator.fit(X_train, Y_train)\n",
    "            \n",
    "            Y_pred = best_estimator.predict(X_test)\n",
    "            rsme = round(np.sqrt(mean_squared_error(Y_test, Y_pred)), 2)\n",
    "            \n",
    "            result = dict(y_true=Y_test, y_pred=Y_pred, best_params=best_params, rsme=rsme,\n",
    "                          seed=self.seed, best_estimator=best_estimator, preprocessor=preprocessor)\n",
    "            \n",
    "            self.stats.append(result)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        data = data.copy()\n",
    "        self.best_preprocessor.transform(data)\n",
    "        return self.best_estimator.predict(data)\n",
    "    \n",
    "    def collect_best_stats(self):\n",
    "        best_rsme = math.inf\n",
    "        total_rsme = 0\n",
    "        best_stats = None\n",
    "        \n",
    "        for stats in self.stats:\n",
    "            rsme = stats['rsme']\n",
    "\n",
    "            total_rsme += rsme\n",
    "            if rsme < best_rsme:\n",
    "                best_rsme = rsme\n",
    "                best_stats = stats\n",
    "        \n",
    "        self.best_stats = best_stats\n",
    "        self.best_estimator = best_stats['best_estimator']\n",
    "        self.best_preprocessor = best_stats['preprocessor'] \n",
    "        self.mean_rsme = total_rsme / len(self.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9afae4-9888-4332-b759-b7a057025508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:   \n",
    "    def __init__(self, name, data, n_splits, test_size, seed, prep_params={}):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.seed = seed\n",
    "        self.prep_params = prep_params\n",
    "        self.estimators = {}\n",
    "    \n",
    "    def set_estimators(self, estimators):\n",
    "        self.estimators = estimators\n",
    "    \n",
    "    def get_model_path(self, name):\n",
    "        return path.join(path_models, f'{self.name}_{name}.pickle')\n",
    "    \n",
    "    def save_model(self, name, model):\n",
    "        model_path = self.get_model_path(name)\n",
    "        with open(model_path,'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "        \n",
    "    def load_model(self, name):\n",
    "        model_path = self.get_model_path(name)\n",
    "        with open(model_path, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "        \n",
    "    def train_estimators(self, **kwargs):\n",
    "        estimators = kwargs.pop('estimators', self.estimators.keys())\n",
    "        for name in estimators:\n",
    "            print_red(f'Estimator: {name}\\n')\n",
    "            model = self.train_estimator(name, **kwargs)\n",
    "            yield (name, model)\n",
    "            \n",
    "    def train_estimator(self, name, reset=False, seed=None, save=True):      \n",
    "        if seed is None:\n",
    "            seed = self.seed\n",
    "        \n",
    "        if not reset:\n",
    "            try:\n",
    "                model = self.load_model(name)\n",
    "                setattr(self, name, model)\n",
    "                \n",
    "                print(f'Model {name} is loaded from disk successfully.')\n",
    "                return model\n",
    "            \n",
    "            except:\n",
    "                model = None\n",
    "        \n",
    "        name, estimator, hp_grid = self.estimators[name]\n",
    "        model = Model(estimator, self.data, self.labels, self.n_splits,\n",
    "                    self.test_size, seed, self.prep_params, hp_grid)\n",
    "        \n",
    "        with PrintDuration() as tick:\n",
    "            model.train(tick)\n",
    "\n",
    "        model.collect_best_stats()\n",
    "        setattr(self, name, model)\n",
    "        \n",
    "        if save:\n",
    "            self.save_model(name, model)\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def search_best_seed(self, name, seed_range=100):\n",
    "        best_rsme = math.inf\n",
    "        best_seed = 0\n",
    "\n",
    "        for seed in range(seed_range):\n",
    "            estimator = self.train_estimator(name, seed, save=False)\n",
    "            rsme = estimator.best_stats[\"rsme\"]\n",
    "\n",
    "            if rsme < best_rsme:\n",
    "                best_rsme = rsme\n",
    "                best_seed = seed\n",
    "                print(f'{seed} -> {rsme} - {estimator.mean_rsme}')\n",
    "        \n",
    "        print(f'Best seed found as {best_seed}')\n",
    "        return best_seed\n",
    "    \n",
    "    def get_results_dataframe(self, name, shuffle=False, ascending=False):\n",
    "        model = getattr(self, name)\n",
    "\n",
    "        true = model.best_stats['y_true'].reshape(-1)\n",
    "        pred = model.best_stats['y_pred'].reshape(-1)\n",
    "        \n",
    "        df = pd.DataFrame(data={\n",
    "            'true': true,\n",
    "            'prediction': pred,\n",
    "            'diff': np.absolute(true - pred)\n",
    "        })\n",
    "    \n",
    "        if shuffle:\n",
    "            df = df.sample(frac=1)\n",
    "        else:\n",
    "            df = df.sort_values('diff', ascending=ascending)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def print_stats(self, name):\n",
    "        model = getattr(self, name)\n",
    "        print('best_rsme', model.best_stats['rsme'])\n",
    "        print('mean_rsme', model.mean_rsme)\n",
    "        print('best_params', model.best_stats['best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad29e17-8d15-479f-ac58-f0280a4dc83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTrainer:\n",
    "    def __init__(self):\n",
    "        self.estimators = {}\n",
    "        self.trainer_names = []\n",
    "        \n",
    "    def add_estimator(self, name, estimator, hp_grid=None):\n",
    "        self.estimators[name] = (name, estimator, hp_grid)\n",
    "        \n",
    "    def add_trainer(self, **kwargs):\n",
    "        name = kwargs['name']\n",
    "        trainer = Trainer(**kwargs)\n",
    "        trainer.set_estimators(self.estimators)\n",
    "        \n",
    "        self.trainer_names.append(name)\n",
    "        setattr(self, name, trainer)\n",
    "        \n",
    "    def run_trainer(self, name, **kwargs):\n",
    "        trainer = getattr(self, name)\n",
    "        for (model_name, model) in trainer.train_estimators(**kwargs):\n",
    "            yield (name, trainer, model_name, model)\n",
    "            \n",
    "    def run_all_trainers(self, **kwargs):\n",
    "        trainers = kwargs.pop('trainers', self.trainer_names)\n",
    "        count = len(trainers)\n",
    "        \n",
    "        for index, name in enumerate(trainers):\n",
    "            print_blue(f'Trainer {index+1}/{count}: {name}\\n')\n",
    "            for (trainer_name, trainer, model_name, model) in self.run_trainer(name, **kwargs):\n",
    "                yield (trainer_name, trainer, model_name, model)\n",
    "    \n",
    "set_trainer = SetTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c033179c-4f7a-449a-a301-5301cbe94531",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196d5ae-3b88-48e3-b305-8e2dc53e80ab",
   "metadata": {},
   "source": [
    "### Preprocessor Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559534ba-0e59-4ec5-84f2-63bd06eb2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prep_params(override={}):\n",
    "    defaults = {\n",
    "        'target': 'HeartDisease',\n",
    "        'outlier_strategy': 'all',\n",
    "        'encode_labels': True,\n",
    "        'onehot_encoding': ['Race', 'Diabetic'],\n",
    "        'ordinal_encoding': {\n",
    "            'GenHealth': ['Poor', 'Fair', 'Good', 'Very good','Excellent'],\n",
    "            'AgeCategory': ['18-24', '25-29','30-34', '35-39', '40-44', '45-49', '50-54',\n",
    "                                '55-59', '60-64', '65-69', '70-74', '75-79', '80 or older']\n",
    "            }\n",
    "    }\n",
    "    \n",
    "    return merge(defaults, override)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac4266-3809-4fc6-9b64-b12e26d554c9",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8d6c5-940b-432e-9f23-3fce89762671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_importances(data, n_splits, test_size, seed, prep_params={}):\n",
    "    model = Model(RandomForestClassifier, data, n_splits, test_size, seed, prep_params)\n",
    "    model.train()\n",
    "    return\n",
    "    model.collect_best_stats()\n",
    "    \n",
    "    importances = model.best_estimator.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [df.columns.to_list()[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()\n",
    "    \n",
    "calculate_feature_importances(data=data, n_splits=hp_cv_splits,\n",
    "                              test_size=hp_test_size, seed=hp_seed,\n",
    "                              prep_params=create_prep_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e4b8d-e880-48f1-85c8-c1c0b59ce133",
   "metadata": {},
   "source": [
    "### Explained Variance Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f055e-c2b1-456b-9022-c1aea58d570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_explained_variance_ratio(data, p=0.95):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X = scaler.fit_transform(data)\n",
    "    \n",
    "    pca = PCA(n_components=None, svd_solver='full', copy=True)\n",
    "    reduced = pca.fit_transform(X)\n",
    "    \n",
    "    # extract the smallest number of components which\n",
    "    # explain at least p% (e.g. 80%) of the variance\n",
    "    n_components = 1 + np.argmax(np.cumsum(pca.explained_variance_ratio_) >= p)\n",
    "    print(f'For p={int(p*100)}% n_components should be {n_components}\\n')\n",
    "\n",
    "    # extract the values of the selected components\n",
    "    #Z = pca.transform(X)[:, :n_components]\n",
    "    \n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    \n",
    "calculate_explained_variance_ratio(data, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6438daf-1ae4-42b0-8371-e7d412edb454",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfec1e7-6783-405b-9838-55e1dbcad914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4100e5b2-fcb5-4165-b525-008fe573ebaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36468257-ab77-4496-9b25-da7630dc57eb",
   "metadata": {},
   "source": [
    "### Default Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b04ba-7138-4a79-8be0-db54c94c45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_params = create_prep_params({\n",
    "    'outlier_strategy': 'all',\n",
    "    'encode_labels': True,\n",
    "})\n",
    "\n",
    "set_trainer.add_trainer(name='default', data=data, n_splits=hp_cv_splits,\n",
    "                        test_size=hp_test_size, seed=hp_seed, prep_params=prep_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
